{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Active Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from mclearn.experiment import ActiveExperiment, load_results, save_results\n",
    "from mclearn.tools import log\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "warnings.filterwarnings('ignore')  # Ignore annoying numpy warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Setup:\n",
    "\n",
    "* 20-fold stratified shuffled split cross validation\n",
    "* training pool size: 70% of data up to a maximum of 10,000 examples\n",
    "* test pool size: the remaining examples up to a maximum of 20,000\n",
    "* use logistic regression with gaussian kernel approximation and L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_EXPERIMENTS = False\n",
    "uci_sets = ['glass', 'ionosphere', 'magic', 'miniboone',\n",
    "            'pageblocks', 'pima', 'sonar', 'vehicle', 'wpbc',\n",
    "            'yeast', 'semeion'] \n",
    "datasets =  sorted(uci_sets + ['sdss'])\n",
    "methods_al =  ['passive', 'margin', 'w-margin', 'confidence',\n",
    "            'w-confidence', 'entropy', 'w-entropy',\n",
    "            'qbb-margin', 'qbb-kl', 'passive']\n",
    "methods_bandits = ['thompson', 'ocucb', 'klucb', 'exp++',]\n",
    "methods_rank = ['borda', 'geometric', 'schulze']\n",
    "methods = methods_al + methods_bandits + methods_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_expt(X, y, dataset, scale=True):\n",
    "    log(dataset, end='')\n",
    "    for method in methods:\n",
    "        log('.', end='')\n",
    "        expt = ActiveExperiment(X, y, dataset, method, scale, n_splits=20)\n",
    "        expt.run_policies()\n",
    "    \n",
    "    expt = ActiveExperiment(X, y, dataset, None, scale)\n",
    "    expt.run_asymptote()\n",
    "    log('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    for dataset in uci_sets:\n",
    "        data_path = os.path.join('data', dataset + '.csv')\n",
    "        data = pd.read_csv(data_path)\n",
    "        X, y = data.iloc[:, 1:], data['target']\n",
    "        run_expt(X, y, dataset)\n",
    "\n",
    "    data_path = os.path.join('data', 'sdss.h5')\n",
    "    data = pd.read_hdf(data_path, 'sdss')\n",
    "    class_idx = data.columns.get_loc('class')\n",
    "    X, y = data.iloc[:, (class_idx+1):], data['class']\n",
    "    run_expt(X, y, 'sdss', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    for (i, dataset) in enumerate(datasets):\n",
    "        maximum = {}\n",
    "        measures = ['f1', 'accuracy', 'mpba']\n",
    "        for measure in measures:\n",
    "            asymptote_measure = 'asymptote_' + measure\n",
    "            max_measure = 'max_' + measure\n",
    "            results = {}\n",
    "            for method in methods:\n",
    "                results[method] = load_results(dataset, method, 'mpba', True)\n",
    "            results['asymptote'] = load_results(dataset, 'asymptote', asymptote_measure, True)\n",
    "            maximum[max_measure] = results['asymptote']\n",
    "            for method in methods:\n",
    "                maximum[max_measure] = max(maximum[max_measure], max(results[method]))\n",
    "        save_results(dataset, 'max', maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No passive arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_expt(X, y, dataset, scale=True):\n",
    "    log(dataset, end='')\n",
    "    for method in methods:\n",
    "        log('.', end='')\n",
    "        expt = ActiveExperiment(X, y, dataset, method, scale=scale, passive=False)\n",
    "        expt.run_policies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods =  ['thompson', 'ocucb', 'klucb',\n",
    "            'exp++', 'borda', 'geometric', 'schulze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    for dataset in uci_sets:\n",
    "        data_path = os.path.join('data', dataset + '.csv')\n",
    "        data = pd.read_csv(data_path)\n",
    "        X, y = data.iloc[:, 1:], data['target']\n",
    "        run_expt(X, y, dataset)\n",
    "\n",
    "    data_path = os.path.join('data', 'sdss.h5')\n",
    "    data = pd.read_hdf(data_path, 'sdss')\n",
    "    class_idx = data.columns.get_loc('class')\n",
    "    X, y = data.iloc[:, (class_idx+1):], data['class']\n",
    "    run_expt(X, y, 'sdss', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_strength(asymptote, passive, policy):\n",
    "    deficiency = np.sum(asymptote - policy, axis=1) / np.sum(asymptote - passive, axis=1)\n",
    "    strength = 1 - deficiency\n",
    "    return strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mpba_strength():\n",
    "    fig = plt.figure(figsize=(15, 20))\n",
    "    fig.subplots_adjust(hspace=.6)\n",
    "    for (i, dataset) in enumerate(datasets):\n",
    "        results = {}\n",
    "        for method in methods:\n",
    "            results[method] = load_results(dataset, method, 'mpba', mean=False)\n",
    "        results['max'] = load_results(dataset, 'max', 'max_mpba')\n",
    "        strength_dict = {}\n",
    "        for method in methods:\n",
    "            s = calculate_strength(results['max'], results['passive'], results[method])\n",
    "            strength_dict[method] = s\n",
    "        strength_df = pd.DataFrame(strength_dict)\n",
    "        sorted_cols = (-strength_df.median()).sort_values().index\n",
    "        strength_df = strength_df[sorted_cols]\n",
    "\n",
    "        ax = fig.add_subplot(6, 2, i + 1)\n",
    "        strength_df.index.name = 'trial'\n",
    "        strength_df = strength_df.reset_index()\n",
    "        strength_df = strength_df.melt(id_vars=['trial'], value_vars=methods)\n",
    "        strength_df.loc[strength_df['variable'].isin(methods_al), 'type'] = 'single'\n",
    "        strength_df.loc[strength_df['variable'].isin(methods_bandits), 'type'] = 'bandit'\n",
    "        strength_df.loc[strength_df['variable'].isin(methods_rank), 'type'] = 'rank'\n",
    "        # We could use hue here, but I think there is a bug in seaborn that squishes\n",
    "        # the boxplot\n",
    "        \n",
    "        palette_map = {\n",
    "            **{m: sns.color_palette()[0] for m in methods_al},\n",
    "            **{m: sns.color_palette()[2] for m in methods_bandits},\n",
    "            **{m: sns.color_palette()[1] for m in methods_rank},\n",
    "        }\n",
    "        sns.boxplot(data=strength_df, x='variable', y='value', order=sorted_cols, width=0.5,\n",
    "                    palette=palette_map)\n",
    "        ax.set_title(dataset)\n",
    "#         ax.set_ylim(-0.4, 0.9)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, rotation_mode='anchor', ha='right')\n",
    "        ax.xaxis.set_visible(True)\n",
    "        \n",
    "        # set bar width\n",
    "        new_width = 0.5\n",
    "        for bar in ax.patches:\n",
    "            x = bar.get_x()\n",
    "            width = bar.get_width()\n",
    "            centre = x + new_width / 2.\n",
    "\n",
    "            bar.set_x(centre - new_width / 2.)\n",
    "            bar.set_width(new_width)\n",
    "            \n",
    "    #fig.savefig('strengths.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_sets = ['glass', 'ionosphere', 'magic', 'miniboone',\n",
    "            'pageblocks', 'pima', 'sonar', 'vehicle', 'wpbc'] \n",
    "datasets =  sorted(uci_sets + ['sdss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_mpba_strength()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves():\n",
    "    selected_methods = ['passive', 'confidence', 'borda', 'exp++']\n",
    "    format_as_percent_plot = lambda x, pos: \"{:.0f}%\".format(x * 100)\n",
    "    fig = plt.figure(figsize=(15, 20))\n",
    "    for (i, dataset) in enumerate(datasets):\n",
    "        learning_curves = {}\n",
    "        for method in selected_methods:a\n",
    "            learning_curves[method] = load_results(dataset, method, 'mpba', True)\n",
    "        maximum = load_results(dataset, 'max', 'max_mpba')\n",
    "        sample_size = learning_curves['passive'].shape[0] + 49\n",
    "\n",
    "        ax = fig.add_subplot(4, 3, i + 1)\n",
    "        for method in selected_methods:\n",
    "            xticks = np.arange(50, 50 + len(learning_curves[method]))\n",
    "            ax.plot(xticks, learning_curves[method], label=method, linewidth=1)\n",
    "\n",
    "        ax.legend(loc='lower right', frameon=True)\n",
    "        ax.get_yaxis().set_major_formatter(FuncFormatter(format_as_percent_plot))\n",
    "        ax.set_title(dataset)\n",
    "        ax.tick_params(top='off')\n",
    "\n",
    "        ax.plot([50, sample_size], [maximum, maximum], ls='--', color='#377eb8')\n",
    "        ax.set_xlim(50, sample_size)\n",
    "    fig.savefig('learning_curves.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curves()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
